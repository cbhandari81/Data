---
title: "Twitter Followers Analysis and Prediction"
author: "Chetan Bhandari"
date: "2 May 2016"
output: 
  html_document: 
    fig_height: 6
    fig_width: 8
    theme: cerulean
---

#Final project for Data science syllabus 

#Harvard Extension School

#Problem Statement

Predict the number of follower a user has based on number of tweets, users followed, favorites, geographical location, language, data joined, etc.

#Data Insights

####"twitteR" package

We get the data from Twitter site using the 'twitteR' package of R. Also, the analysis has been done using R programming. 

The twitter API is rate restricted, so it can take a good couple of hours to download 100k users depending on your internet speed. The test data for this experiment can be found here:

"https://raw.githubusercontent.com/cbhandari81/data/master/final%20project/twitter_s_en.csv"

Next we study the data. 

The data that we get from Twitter API using "twitteR" package are:

 [1] "description"               
 [2] "statusesCount"             
 [3] "followersCount"   
 [4] "favoritesCount"          
 [5] "friendsCount"               
 [6] "url"              
 [7] "name"                        
 [8] "created"                        
 [9] "protected"        
[10] "verified"                  
[11] "screenName"               
[12] "location"         
[13] "lang"                       
[14] "id"                               
[15] "listedCount"      
[16] "followRequestSent" 
[17] "profileImageUrl"  

The variables that are useful in predicting the followers from above are :

[2] statusesCount : Number of tweets by a user.
[4] favoritesCount : Number of tweets the user has added as favorites. This can give us a picture of his activity trend.  
[5] friendsCount : Number of other users this user is following
[8] created : When the account was first created.
[12] location : Geographical location of a user. However, since very less people have mentioned this in their profiles and also since the value for this can be anything, e.g. Washington, Washing DC, US, NY, SF, SFO, Bangalore, BLR, its quite a job to wrangle this and convert to meaningful locations. We are therefore not considering this variable. 
[13] lang : Language the user operates in. This is 'EN' only in our dataset.
'followRequestSent' is FALSE 99% and 'profileImageURL' is nothing but the link to users profile. 

####Initial Findings

There is a good correlation (0.61) between followers and friends. 
Another interesting part is that the number of tweets the user makes does not have a good correlation with followers. Its only 0.16.  We therefore think that its not only the number of tweets but the subject and sentiment of the tweet also that matters and has an influence on the followers. 
Created has negative correlation as expected.

####New data and modifications to the data set

The general trend of users is to have more friends than followers, or have similar number. However there is a group of users who have many followers but very less friends. These users are generally either companies/organizations, like Apple, Microsoft, or popular personalities/celebrities like Angelina Jolie, Trump, Pete Sampras (remember him ?) etc.

  Twitter does not have any data that differentiates individual users vs groups, therefore , we created a new variable 'cc'. We set this variable to TRUE or 1 whenever the user has more than 5000 followers, or when the number of followers is more than 20 times the number of friends. Out of 100k users, there were 16.8k users that belonged to this category !


#Limitations and tips on how to improve prediction

####The data that we have used for this experiment is for english speaking users only 'en'. For other users the trend might be different. 
The data from twitter is quite limited, and predicting the followers count from the data Twitter shares publicly, is quite a challenge. For e.g. a user has 100 friends but can have 50 followers, another user can have 100 followers for 100 friends. We have therefore used multiple algorigthms to help predict data. 

When predicting the user's followers, what we feel would be really good to have, to correctly predict are the following : 

1. Type of User : Individual or Organization.
2. User's recent and past activity in terms of number of logins in the past weeks, month or year. 
3. Number of tweets and re-tweets. (we have this)
4. Number of friends or groups that he/she is connected with. (have this again)
5. Sentiment of users tweets. Positive sentiments will attract more followers. 
6. Gender. Sometimes this also helps in predicting the trend.  
7. Also if location can be maintained as city and country, we can use that to categorize as well. This is currently just a string and user can enter anything. Its mostly junk. 

It all depends on kind of people and cause (subject) the user is following and his level of activity on twitter. Number of tweets the user has, seems like a good enough does not have 

#Approaches followed here

We are using the following 4 approaches :

1. K Nearest neighbors (knn3)

2. Linear Regression (lm)

3. Random Forest (randomForest)

4. Quadratic Discriminant Analysis

Since the variance of followers is large, we will be using intervals to predict data. Therefore the algorithm would predict a certain value with an error of <interval value> with a certain % (80% atleast) accuracy. 

The Twitter followers are predicted using the following parameters:

1. No. of tweets (statusesCount).

2. No. of favorites (favoritesCount).

3. No. of people he/she is following (friendsCount).

4. The year the user opened the account with Twitter. (created)

5. Language the user operates in, which is predictive of location. (lang)

5. Parameter denoting whether the user is a Company/Organization OR a Celebrity/popular person. This class of users have very large number of followers in contrast to a regular user, therefore its important to record this classification. (cc)

####Check the Conclusions at the bottom of the page

```{r}
suppressMessages(library(readr))
knitr::opts_chunk$set(echo = TRUE, warning = FALSE)
options(scipen=999)
suppressMessages(library(dplyr))
suppressMessages(library(twitteR))
suppressMessages(library(caret))
suppressMessages(library(lubridate))
suppressMessages(library(MASS))
suppressMessages(library(e1071))
suppressMessages(library(readr))
suppressMessages(library(pROC))
suppressMessages(library(randomForest))
```

####This dataset contains ~101k users as got from Twitterdata.rmd. We also initialize the twitter connection using API from library 'twitteR'
```{r}
dat <- read_csv("https://raw.githubusercontent.com/cbhandari81/data/master/final%20project/twitter_s_en.csv")

Init_twitt <- function() {
  consumer_key <- "aNTRmMXvPzA86nuKgnW8iAdha"
consumer_secret <- "WZgtz4LD8aO5ysFp5G7YmNmAb8LJstANlQw88H76rxzzxbrIBy"
access_token <- "1375379682-kabi92NOLPjVaZnFQPyGIlNcJWjfXtoVFeKoPAc"
access_secret <- "QCxMASRiUWL2PtgXoENxIsMeH2do2QKSslXGTxkgZzFx0"
options(httr_oauth_cache=T) #This will enable the use of a local file to cache OAuth access credentials between R sessions.
setup_twitter_oauth(consumer_key,
                    consumer_secret,
                    access_token,
                    access_secret)

}

Init_twitt()
```

Following is the snapshot of data. 
```{r}
head(dat)
```

We filter the data we need and the first thing we do is to find the correlation coeff.. 
```{r}
tmpk <- data.frame(dat$followersCount, dat$statusesCount, dat$favoritesCount, dat$friendsCount, dat$created) 
colnames(tmpk) <- c("followersCount", "statusesCount", "favoritesCount", "friendsCount", "created" ) 
#process the data
tmpk$created <- as.Date(tmpk$created)
tmpk$created <- year(tmpk$created)
tmpk$statusesCount <- as.double(tmpk$statusesCount)
tmpk$favoritesCount <- as.double(tmpk$favoritesCount)
tmpk$friendsCount <- as.double(tmpk$friendsCount)
tmpk$followersCount <- as.double(tmpk$followersCount)
# Classify Company/Celebrity if the user has followers more than 20 times it has friends , OR if the number of followers are more than 3000.  
tmpk$cc <- ifelse(tmpk$followersCount > 20*tmpk$friendsCount | tmpk$followersCount > 5000, 1, 0)
# Eliminate NAs
tmpk <- na.omit(tmpk)

# Get the correlation coeff.
cor(tmpk)

```

Its pretty clear from the coeff. that the followersCount is directly proportional to friendsCount and cc.  

The 'created' year is inversely proportional as expected as older accounts will generally have more followers than newer ones. However its not a detrimental factor. 

#Prediction Algorithms

### K NEAREST NEIGHBORS

We first get all the parameters that we need in tmpk variable.
```{r}

calc_knn <- function(interval) {
tmpk <- data.frame(dat$followersCount, dat$statusesCount, dat$favoritesCount, dat$friendsCount, dat$created)
colnames(tmpk) <- c("followersCount", "statusesCount", "favoritesCount", "friendsCount", "created")

tmpk$cc <- ifelse(tmpk$followersCount > 20*tmpk$friendsCount | tmpk$followersCount > 5000, 1, 0)
tmpk <- na.omit(tmpk)

tmpk$followersCount <- as.factor(tmpk$followersCount)
tmpk$created <- as.Date(tmpk$created)
tmpk$created <- year(tmpk$created)
tmpk$statusesCount <- as.double(tmpk$statusesCount)
tmpk$favoritesCount <- as.double(tmpk$favoritesCount)
tmpk$friendsCount <- as.double(tmpk$friendsCount)

inTrain <- createDataPartition(y = tmpk$followersCount, p=0.9)
train_set <- slice(tmpk, inTrain$Resample1)
test_set <- slice(tmpk, -inTrain$Resample1)

fit <- knn3(followersCount~., data=train_set, k=5)
predk <- as.double(predict(fit, newdata = test_set, type = "class"))
test_set$followersCount <- as.double(test_set$followersCount)
predk <- ifelse(abs(predk-test_set$followersCount) < interval, test_set$followersCount, predk)

roc_knn <- roc(as.double(test_set$followersCount), predk)
#plot(roc_knn)
return(roc_knn$auc)
}

#func <- function(interval){
#  return(mean(replicate(5, calc_knn(interval))))
#}

X <- seq(0,100, 10)
Y <- sapply(X, calc_knn)
plot(X,Y, type = "b", ylab = "Accuracy", xlab = "Division Interval", main = "K nearest neighbors")

```

The ROC curve with as-is followersCount will not show much accuracy since the variance is high and no of factors is very large. 

We are therefore using intervals so that the test data is contained and we get better accuracy. Using this method we achieve an average accuracy of >80% for interval = 30.

####Therefore, in other words, there is a 80% accuracy that the KNN prediciton will be within 30 counts of actual followers count and ~90% for interval of 80 counts.


### Linear Regression

The linear regression here is divided into 2 parts. 

1. No. of followers in training data is less than 5000, and

2. Above 5000 followers. 

####1. Less than 5000
Since, the followers variance is much lesser in category 1, the linear regression fit gives a much higher accuracy. Above 5000 the deviation is much higher and the accuracy is minimal. 

```{r}
calc_acc <- function(interval) {
tmpk <- data.frame(dat$followersCount, dat$statusesCount, dat$favoritesCount, dat$friendsCount, dat$created)
colnames(tmpk) <- c("followersCount", "statusesCount", "favoritesCount", "friendsCount", "created") 
# calculate the cc variable as mentioned above.
tmpk$cc <- ifelse(tmpk$followersCount > 20*tmpk$friendsCount | tmpk$followersCount > 5000, 1, 0)
# filter the data where the users are no Compnay / Celebrity
tmpk <- filter(tmpk, cc == 0)
tmpk <- na.omit(tmpk)

tmpk$created <- as.Date(tmpk$created)
tmpk$created <- year(tmpk$created)

inTrain <- createDataPartition(y = tmpk$followersCount, p=0.9)
train_set <- slice(tmpk, inTrain$Resample1)
test_set <- slice(tmpk, -inTrain$Resample1)

fit <- lm(followersCount~., data = train_set)
predlm <- round(predict(fit, newdata = test_set) )
# lot of predictions are negative that actually point to a zero so we amend that
predlm <- ifelse(predlm<0, 0, predlm)

# here we check for distance with interval
predlm <- ifelse(abs(predlm-test_set$followersCount) < interval, test_set$followersCount, predlm)

#generate ROC and return the Area Under Curve (auc)
roc_lm <- roc(response = test_set$followersCount, predictor = predlm)
return(roc_lm$auc)
#plot(roc_lm)
}
func <- function(interval){
  return(mean(replicate(5, calc_acc(interval))))
}
X <- seq(100, 1000, 100)
Y <- sapply(X, func)
# Y values are 
Y
plot(X,Y, type = "b", ylab = "Accuracy", xlab = "Division Interval", main = "Linear Regression for regular users")

```

As per ROC data above, at an average there is >80% accuracy that the followers count predicted by linear regression above, is within 400 counts of the actual value and ~90% for within 600 counts. 



####2. More than 5000
Above 5000 the deviation is much higher and the accuracy is minimal. 


```{r}
calc_acc_cc <- function(interval) {
tmpk <- data.frame(dat$followersCount, dat$statusesCount, dat$favoritesCount, dat$friendsCount, dat$created)
colnames(tmpk) <- c("followersCount", "statusesCount", "favoritesCount", "friendsCount", "created")
# calculate the cc variable as mentioned above.
tmpk$cc <- ifelse(tmpk$followersCount > 20*tmpk$friendsCount | tmpk$followersCount > 5000, 1, 0)
# filter the data where the users are no Compnay / Celebrity
tmpk <- filter(tmpk, cc == 1)
tmpk <- na.omit(tmpk)

tmpk$created <- as.Date(tmpk$created)
tmpk$created <- year(tmpk$created)

inTrain <- createDataPartition(y = tmpk$followersCount, p=0.9)
train_set <- slice(tmpk, inTrain$Resample1)
test_set <- slice(tmpk, -inTrain$Resample1)

fitcc <- lm(followersCount~., data = train_set)
predlmcc <- round(predict(fitcc, newdata = test_set) )
predlmcc <- ifelse(predlmcc<0, 0, predlmcc)

predlmcc <- ifelse(abs(predlmcc-test_set$followersCount) < interval, test_set$followersCount, predlmcc)
# Somehow the ROC was not working for this data set, so had to use a workaround.This is a mean where the predicted data = test data. Note the interval is 20000. 
return(mean(test_set$followersCount == predlmcc))
}
func <- function(interval){
  return(mean(replicate(5, calc_acc_cc(interval))))
}

X <- seq(2000, 40000, 2000)
Y <- sapply(X, func)
plot(X,Y, type = "b", ylab = "Accuracy", xlab = "Division Interval", main = "Linear Regression for Company/Celebrity")

```

As per data above, at an average there is 80% accuracy, where the followers count predicted by linear regression above, is within 30,000 counts of the actual value. 
Therefore linear regression will not give a good estimate if the user is a company/group or celebrity/popular.


###Random Forest

```{r}
calc_rfa <- function(interval) {
tmpk <- data.frame(dat$followersCount, dat$statusesCount, dat$favoritesCount, dat$friendsCount, dat$created)
colnames(tmpk) <- c("followersCount", "statusesCount", "favoritesCount", "friendsCount", "created")
tmpk$cc <- ifelse(tmpk$followersCount > 20*tmpk$friendsCount | tmpk$followersCount > 5000, 1, 0)
tmpk <- na.omit(tmpk)
tmpk$created <- as.Date(tmpk$created)
tmpk$created <- year(tmpk$created)
# Using temporary data set of 10,000 as the Fit model for RFA becomes very large for 100k users.
tmpk <- sample_n(tmpk, 1000)
inTrain <- createDataPartition(y = tmpk$followersCount, p=0.9)
train_set <- slice(tmpk, inTrain$Resample1)
test_set <- slice(tmpk, -inTrain$Resample1)


fitrfa <- randomForest(formula = followersCount~., data = train_set)
predrfa <- round(predict(fitrfa, newdata = test_set))
predrfa <- ifelse(predrfa < 0, 0, predrfa)

predrfa <- ifelse(abs(predrfa-test_set$followersCount) < interval, test_set$followersCount, predrfa)
rocrfa <- roc(response = test_set$followersCount, predictor = predrfa)
return(rocrfa$auc)
#plot(rocrfa)
}

func <- function(interval){
  return(mean(replicate(10, calc_rfa(interval))))
}

X <- seq(10,100, 10)
Y <- sapply(X, func)
plot(X,Y, type = "b", ylab = "Accuracy", xlab = "Division Interval", main = "Random Forest")

```

####When using Random forest, the accuracy is around 85% that the predicted followers would be within 40 counts of actual value.


### Quadratic Discriminant Analysis

Considering ony Numeric values here.
```{r}
calc_qda <- function(interval){

tmpk <- data.frame(dat$followersCount, dat$statusesCount, dat$favoritesCount, dat$friendsCount, dat$created)
colnames(tmpk) <- c("followersCount", "statusesCount", "favoritesCount", "friendsCount", "created")
tmpk <- na.omit(tmpk)

tmpk$created <- as.Date(tmpk$created)
tmpk$created <- year(tmpk$created)

tmpk$followersCount <- as.double(tmpk$followersCount)
tmpk$statusesCount <- as.double(tmpk$statusesCount)
tmpk$favoritesCount <- as.double(tmpk$favoritesCount)
tmpk$friendsCount <- as.double(tmpk$friendsCount)

tmpk$followersCount <- round(tmpk$followersCount/interval)
tmpk$followersCount <- ifelse(tmpk$followersCount >= 20, 20, tmpk$followersCount)

inTrain <- createDataPartition(y = tmpk$followersCount, p=0.9)
train_set <- slice(tmpk, inTrain$Resample1)
test_set <- slice(tmpk, -inTrain$Resample1)

fitqda <- qda(formula = followersCount~., data = train_set)
predqda <- as.double(predict(fitqda, newdata = test_set)$class)
predqda <- ifelse(predqda < 0, 0, predqda)

rocqda <- roc(response = test_set$followersCount, predictor = predqda)
return(rocqda$auc)

}
X <- seq(1000, 10000, 2000)
Y <- sapply(X, calc_qda)
plot(X,Y, type = "b", ylab = "Accuracy", xlab = "Division Interval", main = "Quadratic Discriminant Analysis")

```

As seen above at around 7000, we achieve an >80% accuracy. Therefore QDA will give us an 80% accurate answer with a deviation of 7000 from actual value. Not exactly a good approach to find specific values.


#Conclusion

The best approaches in order of accuracy are : 

1. K nearest neighbors

2. Random Forest

3. Linear Regression

4. Quadratic Discriminant Analysis

----